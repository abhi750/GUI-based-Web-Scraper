# Scrapify v1.0.10

This is a Web Application developed using Python which can scrap Data from the web and save the extracted Data in Google Cloud Storage. It's also very convenient to use, even for a Non-Technical Person as it provides a really nice UI. 

## To check out the live version of my project, [Click Here...](https://abhi777-scrapify-scrapify-405j5r.streamlit.app/)

![image](https://user-images.githubusercontent.com/74459400/228037804-3ecbae64-4b28-4426-8553-605c4289ab49.png)


First, We need to signup by clicking on the Sign Up section present in the side bar and Login using the newly created credentials.

![image](https://user-images.githubusercontent.com/74459400/228038014-1eb0a80f-56a8-484e-84ca-590233e69c7d.png)
![image](https://user-images.githubusercontent.com/74459400/228038226-d58af762-99c0-415a-8a14-592ab748cc4e.png)



It needs various inputs like:
* Name of the GCS Bucket
* A text file containing a list of links of webpages line by line
* A json file containing the credentials of the GCS(Google Cloud Storage)
* Types of Data to be scraped



Executing the script after providing the inputs would start saving the required data into the GCS Bucket.        

![image](https://user-images.githubusercontent.com/74459400/228039201-0635f308-35e3-40f3-ab28-dcb349bcbf4d.png)


![image](https://user-images.githubusercontent.com/74459400/228039553-6a94a001-d149-4b33-b8c2-f652b279dc6f.png)


![6](https://user-images.githubusercontent.com/74459400/199220198-f804d363-4d2b-49de-aa54-333f5243e796.jpg)


                      
